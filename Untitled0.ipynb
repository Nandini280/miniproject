{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJnHh+mcaaQVWtd/9iv5GD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nandini280/miniproject/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qjv6CE-wkVak"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_datasets==4.9.3 -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "lPps75bunQW5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet', with_info=True)"
      ],
      "metadata": {
        "id": "laRfzxCQnfMD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOW-01-vnmno",
        "outputId": "85c3e78b-ab14-4d13-b9e5-6c40726cf73f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='oxford_iiit_pet',\n",
              "    full_name='oxford_iiit_pet/3.2.0',\n",
              "    description=\"\"\"\n",
              "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
              "    images for each class. The images have large variations in scale, pose and\n",
              "    lighting. All images have an associated ground truth annotation of breed.\n",
              "    \"\"\",\n",
              "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
              "    data_dir='/root/tensorflow_datasets/oxford_iiit_pet/3.2.0',\n",
              "    file_format=tfrecord,\n",
              "    download_size=773.52 MiB,\n",
              "    dataset_size=774.69 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'file_name': Text(shape=(), dtype=string),\n",
              "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=37),\n",
              "        'segmentation_mask': Image(shape=(None, None, 1), dtype=uint8),\n",
              "        'species': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
              "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
              "    },\n",
              "    citation=\"\"\"@InProceedings{parkhi12a,\n",
              "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
              "      title        = \"Cats and Dogs\",\n",
              "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
              "      year         = \"2012\",\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYtFzpdlntM0",
        "outputId": "6a2eb5dd-5ea9-4c41-8fdc-b771d73a0f38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <_PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>,\n",
              " 'test': <_PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image, input_mask):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask = input_mask - 1 # convert to zero based indexing\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_train_images(sample):\n",
        "    # resize the image\n",
        "    input_image = tf.image.resize(sample['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(sample['segmentation_mask'], (128, 128))\n",
        "    # data augmentation\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    # normalize the images\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_test_images(sample):\n",
        "    # resize the image\n",
        "    input_image = tf.image.resize(sample['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(sample['segmentation_mask'], (128, 128))\n",
        "    # normalize the images\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "id": "qAQ2Oc8HnxZa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train'].map(load_train_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = dataset['test'].map(load_test_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Zb2RPUOcn_AJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "aqlG1XaroBZZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample(image_list):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(image_list)):\n",
        "        plt.subplot(1, len(image_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(image_list[i]))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OA6F-tEYoEXf"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}