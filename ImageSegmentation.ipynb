{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hqITLuaIEwiZ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_datasets==4.9.3 -q\n"
      ],
      "id": "hqITLuaIEwiZ"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "z185RTQCfZt_"
      },
      "id": "z185RTQCfZt_",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet', with_info=True)"
      ],
      "metadata": {
        "id": "R6Dr0HDUfmWt"
      },
      "id": "R6Dr0HDUfmWt",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXU6M0iBhq4t",
        "outputId": "bc1f7b7f-674b-4aee-dd3f-cc082a4d135e"
      },
      "id": "tXU6M0iBhq4t",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='oxford_iiit_pet',\n",
              "    full_name='oxford_iiit_pet/3.2.0',\n",
              "    description=\"\"\"\n",
              "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
              "    images for each class. The images have large variations in scale, pose and\n",
              "    lighting. All images have an associated ground truth annotation of breed.\n",
              "    \"\"\",\n",
              "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
              "    data_dir='/root/tensorflow_datasets/oxford_iiit_pet/3.2.0',\n",
              "    file_format=tfrecord,\n",
              "    download_size=773.52 MiB,\n",
              "    dataset_size=774.69 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'file_name': Text(shape=(), dtype=string),\n",
              "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=37),\n",
              "        'segmentation_mask': Image(shape=(None, None, 1), dtype=uint8),\n",
              "        'species': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
              "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
              "    },\n",
              "    citation=\"\"\"@InProceedings{parkhi12a,\n",
              "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
              "      title        = \"Cats and Dogs\",\n",
              "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
              "      year         = \"2012\",\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "2M3UZpaWh0Gd",
        "outputId": "cb347eb7-ee4c-4bc7-e2bd-7d2f1e94f613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "2M3UZpaWh0Gd",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <_PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>,\n",
              " 'test': <_PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}