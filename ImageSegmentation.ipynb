{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hqITLuaIEwiZ"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_datasets==4.9.3 -q\n"
      ],
      "id": "hqITLuaIEwiZ"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "z185RTQCfZt_"
      },
      "id": "z185RTQCfZt_",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet', with_info=True)"
      ],
      "metadata": {
        "id": "R6Dr0HDUfmWt"
      },
      "id": "R6Dr0HDUfmWt",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXU6M0iBhq4t",
        "outputId": "bc1f7b7f-674b-4aee-dd3f-cc082a4d135e"
      },
      "id": "tXU6M0iBhq4t",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='oxford_iiit_pet',\n",
              "    full_name='oxford_iiit_pet/3.2.0',\n",
              "    description=\"\"\"\n",
              "    The Oxford-IIIT pet dataset is a 37 category pet image dataset with roughly 200\n",
              "    images for each class. The images have large variations in scale, pose and\n",
              "    lighting. All images have an associated ground truth annotation of breed.\n",
              "    \"\"\",\n",
              "    homepage='http://www.robots.ox.ac.uk/~vgg/data/pets/',\n",
              "    data_dir='/root/tensorflow_datasets/oxford_iiit_pet/3.2.0',\n",
              "    file_format=tfrecord,\n",
              "    download_size=773.52 MiB,\n",
              "    dataset_size=774.69 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'file_name': Text(shape=(), dtype=string),\n",
              "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
              "        'label': ClassLabel(shape=(), dtype=int64, num_classes=37),\n",
              "        'segmentation_mask': Image(shape=(None, None, 1), dtype=uint8),\n",
              "        'species': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
              "    }),\n",
              "    supervised_keys=('image', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=3669, num_shards=4>,\n",
              "        'train': <SplitInfo num_examples=3680, num_shards=4>,\n",
              "    },\n",
              "    citation=\"\"\"@InProceedings{parkhi12a,\n",
              "      author       = \"Parkhi, O. M. and Vedaldi, A. and Zisserman, A. and Jawahar, C.~V.\",\n",
              "      title        = \"Cats and Dogs\",\n",
              "      booktitle    = \"IEEE Conference on Computer Vision and Pattern Recognition\",\n",
              "      year         = \"2012\",\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M3UZpaWh0Gd",
        "outputId": "cb347eb7-ee4c-4bc7-e2bd-7d2f1e94f613"
      },
      "id": "2M3UZpaWh0Gd",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <_PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>,\n",
              " 'test': <_PrefetchDataset element_spec={'file_name': TensorSpec(shape=(), dtype=tf.string, name=None), 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}>}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image, input_mask):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask = input_mask - 1 # convert to zero based indexing\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_train_images(sample):\n",
        "    # resize the image\n",
        "    input_image = tf.image.resize(sample['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(sample['segmentation_mask'], (128, 128))\n",
        "    # data augmentation\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    # normalize the images\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_test_images(sample):\n",
        "    # resize the image\n",
        "    input_image = tf.image.resize(sample['image'], (128, 128))\n",
        "    input_mask = tf.image.resize(sample['segmentation_mask'], (128, 128))\n",
        "    # normalize the images\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask"
      ],
      "metadata": {
        "id": "oJnZg6Poh41y"
      },
      "id": "oJnZg6Poh41y",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train'].map(load_train_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = dataset['test'].map(load_test_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "metadata": {
        "id": "JDNmXuVNiEcO"
      },
      "id": "JDNmXuVNiEcO",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "p5QHzDqJiF7D"
      },
      "id": "p5QHzDqJiF7D",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_sample(image_list):\n",
        "    plt.figure(figsize=(10,10))\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(image_list)):\n",
        "        plt.subplot(1, len(image_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(image_list[i]))\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "QCsWRR_0iJAU"
      },
      "id": "QCsWRR_0iJAU",
      "execution_count": 15,
      "outputs": []
    }
  ]
}